import numpy as np
import tensorflow as tf
from tensorflow.keras.models import Sequential, load_model
from tensorflow.keras.layers import LSTM, Dense, Dropout
from tensorflow.keras.optimizers import Adam
from flask import Flask, render_template, jsonify
import random
from sklearn.preprocessing import MinMaxScaler
from collections import Counter, deque
import os
import schedule
import time
import threading
from sklearn.linear_model import SGDRegressor

app = Flask(__name__, static_folder="static", template_folder="templates")

@app.route('/')
def home():
    return render_template('index.html')

@app.route('/favicon.ico')
def favicon():
    return "", 200

MODEL_PATH = "lstm_model.h5"

# âœ… íˆìŠ¤í† ë¦¬ ì €ì¥ (ìµœëŒ€ 100ê°œ)
history = deque(maxlen=100)

# âœ… ë¡œë˜ ë°ì´í„° ë¡œë“œ
def load_lotto_data():
    try:
        print("ğŸ”„ [DEBUG] ë¡œë˜ ë°ì´í„° ë¡œë”© ì¤‘...")
        lotto_data = np.loadtxt('lotto_data.csv', delimiter=',', dtype=int, skiprows=1)
        print(f"âœ… [DEBUG] ë°ì´í„° ë¡œë“œ ì™„ë£Œ, í¬ê¸°: {lotto_data.shape}")
        return lotto_data
    except Exception as e:
        print(f"âŒ Error loading lotto data: {e}")
        raise e

# âœ… ë°ì´í„° ì „ì²˜ë¦¬ í•¨ìˆ˜ (20íšŒì°¨ì”© ë¶„ì„)
def preprocess_data(lotto_data, sequence_length=20):
    X, y = [], []
    for i in range(len(lotto_data) - sequence_length):
        X.append(lotto_data[i:i+sequence_length])
        y.append(lotto_data[i+sequence_length])
    return np.array(X), np.array(y)

# âœ… LSTM ëª¨ë¸ ìƒì„±
def create_lstm_model():
    model = Sequential([
        LSTM(128, activation='relu', return_sequences=True, input_shape=(20, 6)),
        Dropout(0.4),  # âœ… ê³¼ì í•© ë°©ì§€
        LSTM(64, activation='relu', return_sequences=True),  
        Dropout(0.4),  # âœ… ê³¼ì í•© ë°©ì§€
        LSTM(32, activation='relu', return_sequences=False),  
        Dense(6, activation='linear')  # âœ… ìˆ«ì ê· í˜• ìœ ì§€
    ])
    model.compile(optimizer=Adam(learning_rate=0.0005), loss=tf.keras.losses.MeanSquaredError())
    return model

# âœ… LSTM ì˜ˆì¸¡ í•¨ìˆ˜ (50ì„¸íŠ¸)

def generate_lstm_numbers(X, num_predictions=50):
    try:
        if len(X) == 0:
            return [sorted(random.sample(range(1, 46), 6)) for _ in range(num_predictions)]

        if os.path.exists(MODEL_PATH):
            lstm_model = load_model(MODEL_PATH, compile=False)
            lstm_model.compile(optimizer=Adam(learning_rate=0.0005), loss=tf.keras.losses.MeanSquaredError())
        else:
            lstm_model = create_lstm_model()

        lstm_predictions = lstm_model.predict(np.tile(X[-1].reshape(1, 20, 6), (num_predictions, 1, 1)))

        # ğŸ¯ ì˜ˆì¸¡ê°’ ì¡°ì •: ëœë¤ ë…¸ì´ì¦ˆ + í™•ë¥ ì  ìƒ˜í”Œë§ ì ìš©
        lstm_numbers = []
        for pred in lstm_predictions:
            pred = pred + np.random.normal(0, 3.0, size=6)  
            valid_numbers = sorted(set(np.clip(np.round(pred * 45).astype(int), 1, 45)))

            while len(valid_numbers) < 6:
                valid_numbers.append(random.randint(1, 45))

            random.shuffle(valid_numbers)
            lstm_numbers.append(valid_numbers[:6])

        # âœ… í•­ìƒ ë¦¬ìŠ¤íŠ¸ í˜•íƒœ ë³´ì¥ (ì•„ë˜ ì½”ë“œ ì¶”ê°€)
        if isinstance(lstm_numbers, np.ndarray):
            lstm_numbers = lstm_numbers.tolist()
        elif isinstance(lstm_numbers, (np.int32, np.int64, int)):
            lstm_numbers = [[int(lstm_numbers)] * 6 for _ in range(num_predictions)]

        return lstm_numbers

    except Exception as e:
        print(f"âŒ [ERROR] generate_lstm_numbers ì˜¤ë¥˜: {e}")
        return [sorted(random.sample(range(1, 46), 6)) for _ in range(num_predictions)]

# âœ… ë³´ìƒ ê³„ì‚° í•¨ìˆ˜ (ë¡œë˜ ì˜ˆì¸¡ ì •í™•ë„ì— ë”°ë¼ ê°€ì¤‘ì¹˜ ë¶€ì—¬)
def calculate_rewards(predicted_sets, actual_data):
    rewards = []
    for pred in predicted_sets:
        best_score = 0
        for actual in actual_data:
            matches = len(set(pred) & set(actual))
            if matches >= 3:
                score = matches ** 2
            else:
                score = matches
            best_score = max(best_score, score)
        rewards.append(best_score)
    return rewards

# âœ… RL í•™ìŠµ (SGD ê¸°ë°˜ ë³´ìƒ ê°•í™”)
def train_rl_model(lstm_numbers, actual_data):
    rewards = calculate_rewards(lstm_numbers, actual_data)
    X_train = np.array(lstm_numbers)
    y_train = np.array(rewards)

    if len(X_train.shape) == 1 or X_train.shape[1] != 6:
        return None  

    model = SGDRegressor()
    try:
        model.fit(X_train, y_train)
    except Exception:
        model.partial_fit(X_train, y_train)

    return model

# âœ… Monte Carlo ì‹œë®¬ë ˆì´ì…˜ ìµœì í™” (ì¤‘ë³µ ë°©ì§€ ì¶”ê°€)
def monte_carlo_simulation(rl_model, num_simulations=10000):
    print("ğŸ”„ [DEBUG] Monte Carlo ì‹œë®¬ë ˆì´ì…˜ ì‹œì‘...")
    simulated_results = []

    for _ in range(num_simulations):
        sample_numbers = sorted(random.sample(range(1, 46), 6))

        # ğŸ¯ Mutation ì ìš© (20% í™•ë¥ ë¡œ ìˆ«ì 1ê°œ ë³€ê²½)
        if random.random() < 0.2:
            idx = random.randint(0, 5)
            sample_numbers[idx] = random.randint(1, 45)

        score = float(rl_model.predict([sample_numbers])[0])
        simulated_results.append((sample_numbers, score))

    simulated_results.sort(key=lambda x: x[1], reverse=True)
    best_samples = [x[0] for x in simulated_results[:10]]

    # âœ… ìˆ«ì ê· í˜• í•„í„° ì ìš© (ì¤‘ë³µ ë°©ì§€)
    number_counts = Counter(num for group in best_samples for num in group)
    unique_best_samples = []

    for numbers in best_samples:
        adjusted_numbers = sorted(numbers, key=lambda n: number_counts[n])
        unique_best_samples.append(adjusted_numbers[:6])

    # ğŸ¯ ëœë¤ ì„ê¸° (ë„ˆë¬´ ì¼ì •í•œ íŒ¨í„´ ë°©ì§€)
    for sample in unique_best_samples:
        random.shuffle(sample)

    print(f"âœ… [DEBUG] Monte Carlo ìµœì í™” ì™„ë£Œ: {unique_best_samples[:5]}")
    return unique_best_samples[:5]

# âœ… JSON ë³€í™˜ ì˜¤ë¥˜ ë°©ì§€: numpy.int32, numpy.int64, numpy.float64 ë³€í™˜ + ë¦¬ìŠ¤íŠ¸ ì²˜ë¦¬
def convert_to_int(obj):
    """ JSON ì§ë ¬í™” ì˜¤ë¥˜ ë°©ì§€: numpy.int32, numpy.int64 â†’ int ë³€í™˜ + ì¤‘ì²© ë¦¬ìŠ¤íŠ¸ ì²˜ë¦¬ """
    if isinstance(obj, list):  
        return [convert_to_int(item) for item in obj]  
    elif isinstance(obj, np.ndarray):  
        return [convert_to_int(item) for item in obj.tolist()]  
    elif isinstance(obj, (np.int32, np.int64, np.float32, np.float64)):  # âœ… np.int32 ì¶”ê°€
        return int(obj)  
    else:
        return obj  

@app.route('/predict', methods=['GET'])
def predict():
    try:
        print("ğŸ”„ [DEBUG] ë¡œë˜ ë°ì´í„° ë¡œë“œ ì¤‘...")
        lotto_data = load_lotto_data()
        print(f"âœ… [DEBUG] ë°ì´í„° ë¡œë“œ ì™„ë£Œ! ë°ì´í„° í¬ê¸°: {lotto_data.shape}")

        print("ğŸ”„ [DEBUG] ë°ì´í„° ì „ì²˜ë¦¬ ì¤‘...")
        X, y = preprocess_data(lotto_data)
        print(f"âœ… [DEBUG] ë°ì´í„° ì „ì²˜ë¦¬ ì™„ë£Œ! X í¬ê¸°: {X.shape}, y í¬ê¸°: {y.shape}")

        print("ğŸ”„ [DEBUG] LSTM ë²ˆí˜¸ ìƒì„± ì¤‘...")
        lstm_numbers = generate_lstm_numbers(X)
        print(f"âœ… [DEBUG] LSTM ë²ˆí˜¸ ìƒì„± ì™„ë£Œ: {lstm_numbers}")

        print("ğŸ”„ [DEBUG] ê°•í™” í•™ìŠµ ëª¨ë¸ í›ˆë ¨ ì¤‘...")

        # ğŸ”¥ lstm_numbers ë°ì´í„° ê°•ì œ ë³€í™˜ ì¶”ê°€ (í™•ì‹¤í•œ 2ì°¨ì› ë¦¬ìŠ¤íŠ¸ë¡œ!)
        if isinstance(lstm_numbers, np.ndarray):
            lstm_numbers = lstm_numbers.tolist()
        elif isinstance(lstm_numbers, (np.int32, np.int64, int)):
            lstm_numbers = [[int(lstm_numbers)] * 6]
        elif isinstance(lstm_numbers, list) and all(isinstance(x, (np.int32, np.int64, int)) for x in lstm_numbers):
            lstm_numbers = [lstm_numbers]

        # ì¶”ê°€ í™•ì¸
        if not (isinstance(lstm_numbers, list) and isinstance(lstm_numbers[0], list)):
            raise ValueError(f"lstm_numbers ë°ì´í„°ê°€ ì˜ëª»ë¨: {lstm_numbers}")

        print(f"ğŸ“Š [DEBUG] ìµœì¢… ë³€í™˜ëœ LSTM ì˜ˆì¸¡ ê°’: {lstm_numbers}, íƒ€ì…: {type(lstm_numbers)}")

        trained_rl_model = train_rl_model(lstm_numbers, lotto_data)
        if trained_rl_model is None:
            raise ValueError("trained_rl_modelì´ None ì…ë‹ˆë‹¤. ë°ì´í„° í™•ì¸ í•„ìš”.")

        print("âœ… [DEBUG] ê°•í™” í•™ìŠµ ëª¨ë¸ í›ˆë ¨ ì™„ë£Œ!")

        print("ğŸ”„ [DEBUG] ëª¬í…Œì¹´ë¥¼ë¡œ ì‹œë®¬ë ˆì´ì…˜ ì‹¤í–‰ ì¤‘...")
        final_games = monte_carlo_simulation(trained_rl_model, num_simulations=10000)
        print(f"âœ… [DEBUG] ëª¬í…Œì¹´ë¥¼ë¡œ ì‹œë®¬ë ˆì´ì…˜ ì™„ë£Œ! ê²°ê³¼: {final_games}")

        history.appendleft(final_games)

        return jsonify({
            "Optimal Games": convert_to_int(final_games),
            "History": convert_to_int(list(history)),
            "LSTM Predictions": convert_to_int(lstm_numbers)
        })

    except Exception as e:
        print(f"âŒ [ERROR] ì„œë²„ ì˜ˆì¸¡ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        return jsonify({"error": str(e)}), 500

# âœ… LSTM í•™ìŠµ í•¨ìˆ˜ (Epoch ì¦ê°€ 300~500)
def train_lstm_model():
    try:
        print("ğŸ”„ ìµœì‹  ë¡œë˜ ë°ì´í„° ë¡œë“œ ì¤‘...")
        lotto_data = load_lotto_data()
        X, y = preprocess_data(lotto_data)

        print(f"ğŸš€ LSTM ëª¨ë¸ í•™ìŠµ ì‹œì‘ (ë°ì´í„° í¬ê¸°: {X.shape})...")
        model = create_lstm_model()

        # âœ… í•™ìŠµ íšŸìˆ˜ ì¦ê°€ (300~500 Epoch)
        model.fit(X, y, epochs=300, batch_size=16, verbose=1)

        model.save(MODEL_PATH)
        print("âœ… í•™ìŠµ ì™„ë£Œ! ëª¨ë¸ì´ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")

    except Exception as e:
        print(f"âŒ Training Error: {e}")

# âœ… ëª¨ë¸ í•™ìŠµ ìŠ¤ì¼€ì¤„ë§ (ë§¤ì£¼ í† ìš”ì¼ 21:00)
schedule.every().saturday.at("21:00").do(train_lstm_model)

# âœ… ìŠ¤ì¼€ì¤„ ì‹¤í–‰ì„ ìœ„í•œ ìŠ¤ë ˆë“œ
def run_scheduler():
    while True:
        schedule.run_pending()
        time.sleep(60)

if __name__ == '__main__':
    threading.Thread(target=run_scheduler, daemon=True).start()
    app.run(host='0.0.0.0', port=5001, debug=True)
